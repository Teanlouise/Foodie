\documentclass[a4 paper, 12pt]{article}

\title{DECO2500 - INDIVIDUAL REPORT \\ Feedback 1}
\author{Tean-louise Cunningham (42637460)}
\date{17 April 2020}

\usepackage{geometry}
\geometry{margin=2cm}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{xcolor}

\usepackage{appendix}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=black,      
    urlcolor=blue,
}

%\usepackage{standalone}

\setlength{\parindent}{2em}
\setlength{\parskip}{1em}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\section{Low Fidelity Prototype}
The initial research and conceptual design of the low-fidelity prototype were presented as a \href{run:./MindMap.pdf}{mind map} and \href{https://youtu.be/BRX7kF7ynSQ}{presentation}. The purpose of these evaluations is to learn more about the users' needs, confirm that the conceptual model is appropriate for the users, and to provide feedback about design and flow. It is imperative that any misalignment of values or expectations are identified at this early stage before further time is spent on interaction design. Users must be to understand how the system works and it must align with their expectations to be a worthwhile project.

\subsection{Choose Evaluation Method}
The evaluation method chosen for the Low Fidelity Prototype is a combination of Design Walkthrough, Co-design and TAM.

A design walkthrough involves giving the user a task and, without guidance, ask them to complete the task. By observing and documenting how they interact with the system, feedback on how users expect the system to operate and what they they expect the system can be obtained. This feedback provides clearly whether the conceptual model chosen is appropriate to the users mental model. This method was chosen as the steps involved in using the application are almost the same for every instance, and so it is imperative that users are able to intuitively and easily complete these steps (i.e the task) at this early stage of design.

The co-design process generally involves explaining to the user how the system works and asking for their opinion how they would design the features of the application. For this evaluation, at points during the design walkthrough when a user gets stuck, in addition to asking them what the issues are and what they are experiencing, additional co-design practices will be adopted. This includes asking the user what they think she be happening and how they would design this part to be more intuitive. This method was incorporated into the design walkthrough as an extension since the user is in control of instructing the system it is important that they are able to achieve their goal of choosing a place to dine out the way they want it to since it is a process that will be repeated on average twice a week for them. 

TAM consists of a set of questions based on perceived usefulness, perceived ease of use, attitude and intention to use the system. These questions are scaled from 1 (strongly disagree) to 4 (strongly agree). For this evaluation, eight of the questions were selected (at least one from each category). These questions were identified as most relatable to the purpose of the application, without being repetitive. The questions provide quantitative analysis that can assist with identifying problem areas of user acceptance, however by themselves they don't provide the reasoning behind the response. So in addition to these questions, follow up questions will be asked when a response less than strongly agree is selected to gain further insight into the users experience to understand why there is a gap between mental models.

Together these evaluation methods provide a succinct overview of whether at this stage of design that application gives the user what they want, the gaps in the conceptual model and the overall acceptance of the design and flow of the prototype.


\subsection{Evaluation Protocol}
This protocol was created to provide structure and consistency amongst evaluation of participants. The protocol outlines the flow of the evaluation including scripts, instructions and details of notes to be taken. The protocol can be viewed as Appendix A.1

\subsection{Undertake Evaluations}
Due to current measures relating to COVID-19 all evaluations were taken online, unless part of the family unit. Users are invited to a Google Form where they are asked to sign in with their Google Account. From here they can navigate themselves through all aspects of the evaluation. The form can be viewed in Appendix A.2.  

Firstly, the user is introduced to the evaluation process and asked to complete a consent form online. The consent form is then uploaded in the provided section on the form. Secondly, the user is given instructions for the Design Walkthrough and via a link directed to a Google Slides presentation. Here they are given the task and access to navigate through slides depicting different pages of the paper prototype. The presentation is designed so that when users select areas of the paper prototype that are ‘clickable’ they are directed to the appropriate slide with the corresponding page. The presentation can be viewed in Appendix A.3.

Thirdly, whilst completing the task any time they are stuck for a period of time they are asked to stop and follow up questions are asked, including contribution of design as part of the co-design process. Finally, once the user has completed the task they select a link on the presentation that takes them back to the Google Form where they will complete the TAM evaluation. On the form, users will select their answer between 1 and 4 (strongly agree) which will be stored as quantitative results and follow up questions will be asked for further clarification. The results can be viewed in Appendix A.4.

Throughout all sections of this process notes were taken of observations and feedback. These notes can be seen in Appendix A.5.

\subsection{Evaluation Analysis}
From the process of this evaluation, there are a number of key factors that will influence the design of the medium prototype to ensure increased usability and acceptance of the application for the user.
\begin{itemize}
    \item On the list page, users expected to be able to select the restaurant and be taken back to the restaurant information page. At this time the selection on the list page was to select that restaurant to move forward. A suggestion made by a participant during the co-design was to have 'left swipe' to remove from list, 'click' to go to the restaurant page and 'right swipe' to be given directions.
    \item On the interactive map, users expect the filter selection to take them back to the original place. At this time it was to bring up a more detailed version of the same list (with those previously chosen pre-selected). User suggestion was to remove the first screen entirely or have a more detailed list to being with and the filter selection goes back to this page each time.
\end{itemize}

\end{document}